@extends('layout.main')

@section('content')

    <div class="container content">
    
    
      <script>
        function myFunction()
        {            
            document.getElementById("2016_conf").style.display="block";           
        }
      </script>
    
        <div class="row">
            

            <!-- Begin Content -->
            <div class="col-md-12">

<BODY>
<p><b>Objectives:</b></p>
<P>To understand the fundamentals of research areas, where Neuroscience, Machine learning and Engineering interact such as Vision, Audition, Natural Language and Reinforcement learning.</P>
<P class="p11 ft13">This interdisciplinary course will consist of lectures and hands on tutorials and is based on the premise that a two-way interchange between neuroscience and machine learning/AI will be mutually productive. The Lectures will be conducted by the faculty of IIT Madras, interacting with scientists at the Center for Computational Brain Research as well as world renowned international experts visiting the center during the course. The course focuses on four main areas of robust interactions between engineering and neuroscience (Vision, Speech/Audition, Natural Language and Reinforcement Learning) and also includes related topics (classical Machine Learning, Hardware and Statistical Physics).</P>
<P class="p12 ft0"><b>Course Contents:</b></P>
<P class="p13 ft14"><b>Module 1: Vision</b></P>
<ul>
<li><P class="p14 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft15">Classical Computer/Machine vision:</SPAN></P>
<ul><li><P class="p15 ft13"><SPAN class="ft16">•</SPAN><SPAN class="ft17">Feature Extraction: Canny, Corners - Harris & Hessian Affine;</SPAN></P>
<li><P class="p16 ft13"><SPAN class="ft16">•</SPAN><SPAN class="ft17">Image Segmentation: </SPAN><NOBR>Graph-Cut;</NOBR></P>
<li><P class="p16 ft13"><SPAN class="ft16">•</SPAN><SPAN class="ft17">Motion Analysis: - Tracking (MOG), Optical Flow.</SPAN></P>
<li><P class="p17 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft15">Deep learning techniques for:</SPAN></P>
<li><P class="p15 ft13"><SPAN class="ft18">•</SPAN><SPAN class="ft19">Object recognition and detection,</SPAN></P>
<li><P class="p16 ft13"><SPAN class="ft18">•</SPAN><SPAN class="ft19">Depth estimation,</SPAN></P>
<li><P class="p16 ft13"><SPAN class="ft18">•</SPAN><SPAN class="ft19">Video based activity recognition.</SPAN></P></li></li></ul></ul>
<P class="p23 ft14"><b>Module 2: Audition</b></P>
<ul>
<li><P class="p31 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">The Neurobiology of Speech and Hearing,</SPAN></P>
<li><P class="p34 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Machine learning in Audition.</SPAN></P></ul>
<P class="p23 ft14"><b>Module 3: Reinforcement Learning (RL)</b></P>
<ul><li><P class="p24 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Reinforcement Learning: Rewards and returns,</SPAN></P>
<li><P class="p25 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Markov decision process,</SPAN></P>
<li><P class="p24 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Dynamic programming,</SPAN></P>
<li><P class="p25 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Temporal difference learning,</SPAN></P>
<li><P class="p24 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Function approximation, policy gradient approach.</SPAN></P></li></ul>
<P class="p26 ft14"><b>Module 4: Natural Language Processing (NLP)</b></P>
<ul><li><P class="p27 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Challenges in NLP,An intuitive overview of the role of Machine Learning (ML) in NLP tasks like:</SPAN></P>
<ul><li><P class="p28 ft13"><SPAN class="ft18">•</SPAN><NOBR><SPAN class="ft19">Concept-level</SPAN></NOBR> Information Retrieval,</P>
<li><P class="p29 ft13"><SPAN class="ft18">•</SPAN><SPAN class="ft19">Word Sense Disambiguation (WSD),</SPAN></P>
<li><P class="p30 ft13"><SPAN class="ft18">•</SPAN><SPAN class="ft19">Probabilistic Parsing,</SPAN></P>
<li><P class="p30 ft13"><SPAN class="ft18">•</SPAN><SPAN class="ft19">Machine Translation.</SPAN></P></li></li></ul></ul>
&nbsp
<P class="p18 ft20"><b>Additional Topics: Topics in ML </b></P>
<ul><li><P class="p19 ft22"><SPAN class="ft13">∙</SPAN><SPAN class="ft21">Singular Value Decomposition of matrices encoding the Pointwise Mutual Information between words,</SPAN></P>
<li><P class="p20 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft23">Skip gram models for learning word representations,</SPAN></P>
<li><P class="p21 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft23">Global Vectors for words,</SPAN></P>
<li><P class="p22 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft23">Studying the equivalence between SVD and the newer neural network based methods.</SPAN></P></li></ul>
<P class="p12 ft14"> <b>Neurobiology</b></P>
<ul><liL<P class="p31 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Neuroanatomy of the brain: organizational principles, development and evolution;</SPAN></P>
<li><P class="p32 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Microcircuits and Mesocircuits;</SPAN></P>
<li><P class="p33 ft13"><SPAN class="ft13">∙</SPAN><SPAN class="ft24">Action potentials, synapses, neurotransmitters and modulators.</SPAN></P>
&nbsp
</DIV>
<DIV id="page_3">
<DIV id="p3dimg1">

<DIV class="dclr"></DIV>
<P class="p35 ft2"><b>Laboratory and Tutorials</b></P>
<P class="p36 ft25">Fundamentals of Neurobiology Laboratory: Brain dissection; Demonstration of electrophysiological recordings;</P>
<P class="p36 ft1">Fundamentals of Machine Learning and machine Vision Laboratory</P>
&nbsp
<P class="p18 ft26">Evaluation methodology (only over modules above):</P>
<P class="p37 ft29"><SPAN class="ft27">(a)</SPAN><SPAN class="ft28">Students have to read assigned papers and submit reports/scribe notes (30% Marks);</SPAN></P>
<P class="p38 ft29"><SPAN class="ft27">(b)</SPAN><SPAN class="ft30">Wet and computer lab assignments, (as teams), (40% Marks)</SPAN></P>
<P class="p38 ft29"><SPAN class="ft27">(c)</SPAN><SPAN class="ft31">Tutorials and online quizzes – 30%</SPAN></P>
<P class="p39 ft25">Special Invited talks by renowned CCBR (Dr. Partha Mitra, Dr. Mriganka Sur, Dr. Anand Raghunathan) and other International scientists will be given on related areas, such as:</P>
<P class="p41 ft2"><SPAN class="ft2">a:</SPAN><SPAN class="ft32">Visual Neuroscience; Brain Activity Mapping; Neurotechnologies</SPAN></P>
<P class="p41 ft2"><SPAN class="ft2">b:</SPAN><SPAN class="ft32">Hardware for artificial neural networks and machine learning</SPAN></P>
&nbsp
<P class="p42 ft0"><b>Recommended Text Books:</b></P>
<P class="p43 ft34"><SPAN class="ft18">∙</SPAN><SPAN class="ft33">Deep Learning; Ian Goodfellow and Yoshua Bengio and Aaron Courville, An MIT Press book, 2016.</SPAN></P>
<P class="p44 ft34"><SPAN class="ft18">∙</SPAN><SPAN class="ft33">Computer Vision: Algorithms and Applications; Richard Szeliski, Springer- Verlag London Limited, 2011.</SPAN></P>
<P class="p45 ft37"><SPAN class="ft18">∙</SPAN><SPAN class="ft35">Reinforcement Learning: An Introduction; R. S. Sutton and A. G. Barto, MIT Press, 1</SPAN><SPAN class="ft36">st </SPAN>Edn., 1998.</P>
<P class="p37 ft34"><SPAN class="ft18">∙</SPAN><SPAN class="ft33">Neuroscience; Dale Purves; [5</SPAN><SPAN class="ft36">th </SPAN>Edition], Sinauer Associates, Inc., USA, 2012.</P>
<P class="p46 ft34"><SPAN class="ft18">∙</SPAN><SPAN class="ft33">Speech and Language Processing; Daniel Jurafsky, James H. Martin; Prentice Hall Series in Artificial Intelligence; 2</SPAN><SPAN class="ft36">nd </SPAN>Edn., 2013.</P>
<P class="p47 ft12"><b>Reference Books:</b></P>
<P class="p48 ft34"><SPAN class="ft18">∙</SPAN><SPAN class="ft33">ISL - An Introduction to Statistical Learning with Applications in R; Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. Springer. 2013 (7th printing 2017).</SPAN></P>
<P class="p49 ft37"><SPAN class="ft18">∙</SPAN><SPAN class="ft35">Computational Neuroscience of Vision; by Edmund Rolls, Gustavo Deco; Oxford University Press, 1st edition, 2002.</SPAN></P>
<P class="p50 ft34"><SPAN class="ft18">∙</SPAN><SPAN class="ft33">Information, Physics and Computation; Marc Mezard and Andrea Montanari, Oxford University Press, 1</SPAN><SPAN class="ft36">st </SPAN>Edn., 2009.</P>
<P class="p51 ft34"><SPAN class="ft13">∙</SPAN><SPAN class="ft33">Brain Architecture – Understanding the basic plan; Larry Swanson, Oxford University Press, 2</SPAN><SPAN class="ft36">nd </SPAN>Edn., 2012.</P>


For any other queries: please Contact  <a href="mailto:ccbriitmadras@gmail.com">ccbriitmadras@gmail.com</a> 

            </div>
            <!-- End Content -->
        </div>
    </div>


@stop

@section('jscontent')
	
@stop